# PilotScope 빠른 시작 가이드

## 목표
운영 데이터를 기반으로 최적의 쿼리 최적화 알고리즘과 설정을 찾기

---

## 📋 준비물

- [x] PostgreSQL 13.1 설치 및 실행
- [x] 운영 DB 접근 권한
- [x] PilotScope 설치
- [x] Python 3.8+

---

## 🚀 5단계로 시작하기

### Step 1: 운영 쿼리 로그 추출 (15분)

```bash
# 1-1. PostgreSQL 로그 활성화 (이미 활성화되어 있다면 생략)
psql -U postgres -c "ALTER SYSTEM SET log_statement = 'all';"
psql -U postgres -c "SELECT pg_reload_conf();"

# 1-2. 하루 정도 로그 수집 대기
# 로그 위치 확인: SHOW log_directory;

# 1-3. 로그에서 SQL 추출
cd pilotscope
python scripts/extract_queries_from_log.py \
    --input /var/log/postgresql/postgresql.log \
    --output pilotscope/Dataset/Production/ \
    --train-ratio 0.8
```

**결과 확인:**
```bash
ls pilotscope/Dataset/Production/
# production_train.txt  <- 학습용 쿼리
# production_test.txt   <- 테스트용 쿼리
```

---

### Step 2: ProductionDataset 클래스 생성 (5분)

**파일 생성**: `pilotscope/Dataset/ProductionDataset.py`

```python
from pilotscope.Dataset.BaseDataset import BaseDataset
from pilotscope.PilotEnum import DatabaseEnum

class ProductionDataset(BaseDataset):
    """
    실제 운영 환경의 쿼리 워크로드
    """
    sub_dir = "Production"
    train_sql_file = "production_train.txt"
    test_sql_file = "production_test.txt"
    file_db_type = DatabaseEnum.POSTGRESQL
    
    def __init__(self, use_db_type: DatabaseEnum, created_db_name="production_db"):
        super().__init__(use_db_type, created_db_name)
        self.download_urls = None
```

---

### Step 3: Utils에 등록 (5분)

**파일 수정**: `algorithm_examples/utils.py`

```python
# 기존 import 섹션에 추가
from pilotscope.Dataset.ProductionDataset import ProductionDataset

# load_test_sql() 함수에 추가
def load_test_sql(db):
    if "stats_tiny" == db.lower():
        return StatsTinyDataset(DatabaseEnum.POSTGRESQL).read_test_sql()
    # ... 기존 코드 ...
    elif "production" == db.lower():  # 추가!
        return ProductionDataset(DatabaseEnum.POSTGRESQL).read_test_sql()
    else:
        raise NotImplementedError

# load_training_sql() 함수에도 동일하게 추가
def load_training_sql(db):
    if "stats_tiny" == db.lower():
        return StatsTinyDataset(DatabaseEnum.POSTGRESQL).read_train_sql()
    # ... 기존 코드 ...
    elif "production" == db.lower():  # 추가!
        return ProductionDataset(DatabaseEnum.POSTGRESQL).read_train_sql()
    else:
        raise NotImplementedError
```

---

### Step 4: 통합 테스트 실행 (30분 ~ 수시간)

**방법 A: 커맨드라인으로 빠르게 테스트**

```bash
cd test_example_algorithms

# Baseline (AI 없음) 성능 측정
python unified_test.py --algo baseline --db production

# MSCN 알고리즘 테스트 (빠른 버전)
python unified_test.py --algo mscn --db production \
    --epochs 50 \
    --training-size 500 \
    --collection-size 500

# 결과 비교
python unified_test.py --algo baseline mscn --db production --compare
```

**방법 B: JSON Config 파일 사용 (권장)**

1. `test_configs/production_experiment.json` 파일 수정:

```json
{
  "db_config": {
    "db": "your_production_db_name",  // 실제 DB 이름으로 변경
    "db_host": "localhost",
    "db_port": "5432",
    "db_user": "postgres",
    "db_user_pwd": "your_password"  // 실제 비밀번호로 변경
  },
  
  "experiments": [
    {
      "name": "baseline",
      "algorithm": "baseline",
      "dataset": "production"
    },
    {
      "name": "mscn_fast",
      "algorithm": "mscn",
      "dataset": "production",
      "params": {
        "enable_collection": true,
        "enable_training": true,
        "num_collection": 500,
        "num_training": 500,
        "num_epoch": 50
      }
    }
  ]
}
```

2. 실행:

```bash
python unified_test.py --config test_configs/production_experiment.json
```

---

### Step 5: 결과 분석 (10분)

```bash
# 저장된 결과 확인
python ../algorithm_examples/compare_results.py --list

# 최신 결과 비교
python ../algorithm_examples/compare_results.py --latest baseline mscn --db production

# 차트 확인
ls results/comparison_*.png
ls img/*_production.png
```

**결과 해석:**
```
============================================================
Comparison Results (total_time):
============================================================
  mscn           :    45.2341s  ← MSCN 알고리즘 사용
  baseline       :    67.8912s  ← AI 없이 기본 DB 최적화
============================================================
```

→ 이 경우 MSCN이 **33% 성능 향상** (67.89 → 45.23초)

---

## 🔥 고급 사용법

### 여러 알고리즘 비교

```bash
# Baseline, MSCN, Lero 모두 테스트
python unified_test.py \
    --algo baseline mscn lero \
    --db production \
    --compare \
    --epochs 100 \
    --training-size 1000
```

### Cross-Dataset Training

```python
# test_cross_dataset_training.py 생성
from pilotscope.PilotConfig import PostgreSQLConfig
from algorithm_examples.Mscn.MscnPresetScheduler import get_mscn_preset_scheduler
from algorithm_examples.utils import load_test_sql, save_test_result
from pilotscope.Common.TimeStatistic import TimeStatistic

config = PostgreSQLConfig()
config.db = "production_db"

# IMDB 데이터로 학습한 모델을 운영 DB에 적용
scheduler = get_mscn_preset_scheduler(
    config,
    enable_collection=True,
    enable_training=True,
    training_dataset="imdb",  # 학습은 IMDB 데이터로
    num_epoch=100
)

# 운영 DB에서 테스트
sqls = load_test_sql("production")
for i, sql in enumerate(sqls):
    if i % 10 == 0:
        print(f"Progress: {i}/{len(sqls)}")
    TimeStatistic.start('MSCN_IMDB_Trained')
    scheduler.execute(sql)
    TimeStatistic.end('MSCN_IMDB_Trained')

save_test_result("mscn_imdb_trained", "production")
```

```bash
python test_cross_dataset_training.py
```

### Config Sweep (최적 파라미터 찾기)

```bash
# 여러 epoch 조합 테스트
for epoch in 50 100 200; do
    for train_size in 500 1000 2000; do
        echo "Testing: epoch=$epoch, train_size=$train_size"
        python unified_test.py \
            --algo mscn \
            --db production \
            --epochs $epoch \
            --training-size $train_size
    done
done

# 결과 비교
python ../algorithm_examples/compare_results.py --list
```

---

## 📊 예상 결과

### 시나리오 1: E-commerce 애플리케이션
```
알고리즘         | 실행 시간 | 개선율
----------------|----------|-------
Baseline        | 120.5s   | -
MSCN (기본)      | 89.3s    | 26% ↑
MSCN (튜닝)      | 75.2s    | 38% ↑
Lero            | 82.1s    | 32% ↑
```

### 시나리오 2: Analytics Dashboard
```
알고리즘         | 실행 시간 | 개선율
----------------|----------|-------
Baseline        | 245.8s   | -
MSCN            | 198.4s   | 19% ↑
Lero            | 176.3s   | 28% ↑  ← 복잡한 JOIN에 강함
```

---

## 🛠️ 문제 해결

### Q1: "No module named 'ProductionDataset'" 에러
```bash
# utils.py에 import 추가 확인
grep "ProductionDataset" algorithm_examples/utils.py
```

### Q2: 학습이 너무 오래 걸림
```python
# 파라미터 조정:
# - num_collection=500  # 수집 데이터 제한
# - num_training=500    # 학습 데이터 제한
# - num_epoch=50        # Epoch 줄이기
```

### Q3: 메모리 부족
```python
# 배치 처리:
sqls = load_test_sql("production")
for i in range(0, len(sqls), 100):  # 100개씩 처리
    batch = sqls[i:i+100]
    for sql in batch:
        scheduler.execute(sql)
```

### Q4: DB 연결 실패
```python
# pilotscope_conf.json 확인
cat pilotscope/pilotscope_conf.json

# 또는 코드에서 직접 설정
config = PostgreSQLConfig()
config.db_host = "your_host"
config.db_port = "5432"
config.db_user = "your_user"
config.db_user_pwd = "your_password"
```

---

## 📈 다음 단계

### 1. 정밀 튜닝
- Config Sweep으로 최적 파라미터 탐색
- Cross-validation으로 과적합 방지

### 2. 프로덕션 적용
```python
# 최적 모델 선택 후
scheduler = get_mscn_preset_scheduler(
    config,
    enable_collection=False,  # 이미 학습된 모델 사용
    enable_training=False,
    num_epoch=100  # 최적값
)
```

### 3. 주기적 재학습
```python
# 주기적으로 새 데이터로 재학습
from algorithm_examples.Lero.LeroPresetScheduler import get_lero_dynamic_preset_scheduler

scheduler = get_lero_dynamic_preset_scheduler(config)
# 100개 쿼리마다 자동 재학습
```

### 4. 모니터링
```bash
# 성능 변화 추적
watch -n 60 'python compare_results.py --latest baseline mscn'
```

---

## 🎯 체크리스트

- [ ] 운영 쿼리 로그 추출 완료
- [ ] ProductionDataset 클래스 생성
- [ ] utils.py에 production dataset 등록
- [ ] Baseline 성능 측정
- [ ] MSCN/Lero 테스트 실행
- [ ] 결과 비교 및 Best Config 선택
- [ ] 프로덕션 적용 계획 수립

---

## 💡 꿀팁

### 1. 빠른 프로토타이핑
```bash
# 소량의 데이터로 먼저 테스트
python unified_test.py --algo mscn --db production \
    --collection-size 100 \
    --training-size 100 \
    --epochs 10
```

### 2. GPU 사용 (Lero)
```python
import torch
print(f"GPU: {torch.cuda.is_available()}")  # True면 자동으로 GPU 사용
```

### 3. 결과 추적
```bash
# Git으로 실험 결과 버전 관리
git add results/*.json test_configs/*.json
git commit -m "Experiment: MSCN on production (epoch=100)"
```

### 4. 병렬 실행
```bash
# 여러 터미널에서 동시 실행
# Terminal 1
python unified_test.py --algo mscn --db production &

# Terminal 2
python unified_test.py --algo lero --db production &

# 완료 후 비교
wait
python compare_results.py --latest mscn lero
```

---

## 📚 참고 자료

- **상세 문서**: `운영_데이터_기반_최적화_가이드.md`
- **커스텀 데이터셋**: `algorithm_examples/CUSTOM_DATASET_GUIDE.md`
- **결과 관리**: `algorithm_examples/README_RESULTS.md`
- **PilotScope 논문**: `paper/PilotScope.pdf`

---

**문제가 발생하면 이슈를 올리거나 문서를 참고하세요! 🚀**

