# PilotScope 운영 데이터 기반 최적화 - 구현 요약

## 🎯 목표 및 달성 현황

### 요구사항 달성도

| # | 요구사항 | 현재 상태 | 필요한 작업 |
|---|---------|----------|------------|
| 1 | Best config 출력 및 성능 측정 데이터 | ✅ 50% | Config Sweep 기능 추가 필요 |
| 2 | Dataset/Algorithm 쉽게 변경 | ✅ 80% | `unified_test.py` 구현 완료 |
| 3 | 임의의 데이터셋 추가 | ✅ 100% | 가이드 및 스크립트 제공 |
| 4 | 모델 Training Dataset 변경 | ⚠️ 10% | PresetScheduler 수정 필요 |

---

## 📂 생성된 파일 목록

### 1. 문서 (Documentation)

| 파일 | 설명 | 우선순위 |
|-----|------|---------|
| `운영_데이터_기반_최적화_가이드.md` | 전체 아키텍처 및 구현 가이드 | ⭐⭐⭐⭐⭐ |
| `빠른_시작_가이드.md` | 5단계 빠른 시작 가이드 | ⭐⭐⭐⭐⭐ |
| `구현_요약.md` | 이 문서 | ⭐⭐⭐ |

### 2. 스크립트 (Scripts)

| 파일 | 설명 | 구현 상태 |
|-----|------|----------|
| `scripts/extract_queries_from_log.py` | PostgreSQL 로그에서 SQL 추출 | ✅ 완료 |
| `test_example_algorithms/unified_test.py` | 통합 테스트 프레임워크 | ✅ 완료 |

### 3. 설정 파일 (Config)

| 파일 | 설명 | 구현 상태 |
|-----|------|----------|
| `test_configs/production_experiment.json` | 실험 설정 예제 | ✅ 완료 |

### 4. 아직 생성되지 않은 파일 (TODO)

| 파일 | 설명 | 우선순위 |
|-----|------|---------|
| `pilotscope/Dataset/ProductionDataset.py` | 운영 데이터셋 클래스 | 🔴 높음 |
| `algorithm_examples/config_sweep.py` | Config 파라미터 자동 탐색 | 🟡 중간 |
| `algorithm_examples/config_grid.py` | ConfigGrid 클래스 | 🟡 중간 |

---

## 🔨 구현이 필요한 항목

### Priority 1: 운영 데이터 기본 사용 (1-2시간)

#### 1-1. ProductionDataset 클래스 생성
**파일**: `pilotscope/Dataset/ProductionDataset.py`

```python
from pilotscope.Dataset.BaseDataset import BaseDataset
from pilotscope.PilotEnum import DatabaseEnum

class ProductionDataset(BaseDataset):
    sub_dir = "Production"
    train_sql_file = "production_train.txt"
    test_sql_file = "production_test.txt"
    file_db_type = DatabaseEnum.POSTGRESQL
    
    def __init__(self, use_db_type: DatabaseEnum, created_db_name="production_db"):
        super().__init__(use_db_type, created_db_name)
        self.download_urls = None
```

#### 1-2. utils.py 수정
**파일**: `algorithm_examples/utils.py`

**추가할 코드** (2곳):
```python
# 1. Import 추가 (파일 상단)
from pilotscope.Dataset.ProductionDataset import ProductionDataset

# 2. load_test_sql() 함수 수정 (36번째 줄 근처)
def load_test_sql(db):
    # ... 기존 코드 ...
    elif "production" == db.lower():
        return ProductionDataset(DatabaseEnum.POSTGRESQL).read_test_sql()
    else:
        raise NotImplementedError

# 3. load_training_sql() 함수 수정 (23번째 줄 근처)
def load_training_sql(db):
    # ... 기존 코드 ...
    elif "production" == db.lower():
        return ProductionDataset(DatabaseEnum.POSTGRESQL).read_train_sql()
    else:
        raise NotImplementedError
```

---

### Priority 2: Training Dataset 변경 기능 (2-3시간)

#### 2-1. MscnPresetScheduler 수정
**파일**: `algorithm_examples/Mscn/MscnPresetScheduler.py`

**수정 내용**:
```python
def get_mscn_preset_scheduler(config, enable_collection, enable_training, 
                             num_collection=-1, num_training=-1, num_epoch=100,
                             training_dataset="auto"):  # 추가!
    """
    Args:
        training_dataset: 학습에 사용할 데이터셋
          - "auto": config.db와 동일 (기본값)
          - "stats_tiny", "imdb", "production" 등: 지정한 데이터셋
    """
    # ... 기존 코드 ...
    
    pretraining_event = MscnPretrainingModelEvent(
        config, mscn_pilot_model, pretrain_data_save_table,
        enable_collection=enable_collection,
        enable_training=enable_training,
        training_data_file=None,
        num_collection=num_collection,
        num_training=num_training,
        num_epoch=num_epoch,
        training_dataset=training_dataset  # 전달!
    )
    # ...
```

#### 2-2. MscnPretrainingModelEvent 수정
**파일**: `algorithm_examples/Mscn/EventImplement.py`

**수정 내용**:
```python
class MscnPretrainingModelEvent(PretrainingModelEvent):
    def __init__(self, config, bind_pilot_model, data_saving_table,
                 enable_collection=True, enable_training=True,
                 training_data_file=None, num_collection=-1, 
                 num_training=-1, num_epoch=100,
                 training_dataset="auto"):  # 추가!
        super().__init__(config, bind_pilot_model, data_saving_table,
                        enable_collection, enable_training)
        # ... 기존 코드 ...
        self.training_dataset = training_dataset
    
    def iterative_data_collection(self, db_controller, train_data_manager):
        print("start to collect data for MSCN algorithms")
        
        # 학습 데이터셋 결정 (추가!)
        if self.training_dataset == "auto":
            dataset_name = self.config.db
        else:
            dataset_name = self.training_dataset
            print(f"Using custom training dataset: {dataset_name}")
        
        self.sqls = load_training_sql(dataset_name)  # 수정!
        # ... 나머지 기존 코드 유지 ...
```

**동일한 수정을 Lero에도 적용**:
- `algorithm_examples/Lero/LeroPresetScheduler.py`
- `algorithm_examples/Lero/EventImplement.py`

---

### Priority 3: Config Sweep 기능 (4-5시간)

#### 3-1. ConfigGrid 클래스
**새 파일**: `algorithm_examples/config_grid.py`

```python
"""
Config 파라미터 그리드 생성 및 관리
"""

from itertools import product
from typing import Dict, List

class ConfigGrid:
    """
    여러 파라미터 조합을 생성
    
    Example:
        grid = ConfigGrid({
            "num_epoch": [50, 100, 200],
            "num_training": [100, 500, 1000]
        })
        
        for config in grid:
            print(config)
            # {"num_epoch": 50, "num_training": 100}
            # {"num_epoch": 50, "num_training": 500}
            # ...
    """
    
    def __init__(self, param_dict: Dict[str, List]):
        self.param_dict = param_dict
        self.param_names = list(param_dict.keys())
        self.param_values = list(param_dict.values())
    
    def __iter__(self):
        for values in product(*self.param_values):
            yield dict(zip(self.param_names, values))
    
    def __len__(self):
        total = 1
        for values in self.param_values:
            total *= len(values)
        return total
```

#### 3-2. Config Sweep 실행기
**새 파일**: `algorithm_examples/config_sweep.py`

```python
"""
여러 Config 조합을 자동으로 테스트하고 최적 Config 선택

사용법:
    python config_sweep.py \
        --algo mscn \
        --db production \
        --param num_epoch 50 100 200 \
        --param num_training 100 500 1000
"""

import sys
sys.path.append("../")

import argparse
import json
from pathlib import Path

from pilotscope.PilotConfig import PostgreSQLConfig
from pilotscope.Common.Util import pilotscope_exit
from algorithm_examples.config_grid import ConfigGrid
from algorithm_examples.utils import save_test_result, load_test_results
from test_example_algorithms.unified_test import run_single_test, ALGORITHM_REGISTRY


def run_config_sweep(algo_name: str, dataset_name: str, 
                     config_grid: Dict, db_config: PostgreSQLConfig) -> Dict:
    """
    여러 config 조합 테스트 및 최적값 선택
    """
    grid = ConfigGrid(config_grid)
    results = []
    
    print(f"\n🔍 Config Sweep: Testing {len(grid)} configurations")
    print("=" * 60)
    
    for i, params in enumerate(grid, 1):
        print(f"\n[{i}/{len(grid)}] Testing config: {params}")
        
        try:
            result = run_single_test(db_config, algo_name, dataset_name, params)
            if result:
                results.append(result)
        except Exception as e:
            print(f"❌ Config failed: {e}")
        finally:
            pilotscope_exit()
    
    # 최적 config 선택
    if not results:
        print("\n❌ No successful results")
        return None
    
    best_result = min(results, key=lambda x: x["elapsed_time"])
    
    print("\n" + "=" * 60)
    print("🏆 Best Configuration Found!")
    print("=" * 60)
    print(f"Algorithm: {best_result['algorithm']}")
    print(f"Dataset:   {best_result['dataset']}")
    print(f"Time:      {best_result['elapsed_time']:.2f}s")
    print(f"Params:    {best_result['params']}")
    print("=" * 60)
    
    # 결과 저장
    sweep_result_file = Path("results") / f"sweep_{algo_name}_{dataset_name}.json"
    with open(sweep_result_file, 'w') as f:
        json.dump({
            "best_config": best_result,
            "all_results": results
        }, f, indent=2)
    
    print(f"\n💾 Sweep results saved: {sweep_result_file}")
    
    return best_result


def main():
    parser = argparse.ArgumentParser(description='Config parameter sweep')
    parser.add_argument('--algo', required=True, help='Algorithm name')
    parser.add_argument('--db', required=True, help='Dataset name')
    parser.add_argument('--param', nargs='+', action='append',
                       help='Parameter grid: --param num_epoch 50 100 200')
    
    args = parser.parse_args()
    
    # Config grid 파싱
    config_grid = {}
    if args.param:
        for param_spec in args.param:
            param_name = param_spec[0]
            param_values = [int(v) if v.isdigit() else v for v in param_spec[1:]]
            config_grid[param_name] = param_values
    
    # DB Config
    db_config = PostgreSQLConfig()
    db_config.db = args.db
    
    # Sweep 실행
    run_config_sweep(args.algo, args.db, config_grid, db_config)


if __name__ == '__main__':
    main()
```

---

## 🚀 사용 시나리오

### 시나리오 1: 빠른 시작 (30분)

```bash
# 1. 로그 추출
python scripts/extract_queries_from_log.py \
    --input /var/log/postgresql/postgresql.log \
    --output pilotscope/Dataset/Production/

# 2. ProductionDataset 클래스 생성 (위 Priority 1 참고)

# 3. utils.py 수정

# 4. 테스트 실행
cd test_example_algorithms
python unified_test.py --algo baseline mscn --db production --compare
```

### 시나리오 2: Cross-Dataset Training (1시간)

```bash
# Priority 2 구현 완료 후

# IMDB로 학습 → 운영 DB 테스트
python test_cross_dataset_training.py
```

### 시나리오 3: 최적 Config 찾기 (2-3시간)

```bash
# Priority 3 구현 완료 후

# Config sweep 실행
python algorithm_examples/config_sweep.py \
    --algo mscn \
    --db production \
    --param num_epoch 50 100 200 \
    --param num_training 100 500 1000 \
    --param num_collection 100 500 1000

# 결과 확인
cat results/sweep_mscn_production.json
```

---

## 📊 예상 결과

### 기본 테스트 (Baseline vs MSCN)

```
============================================================
Comparison Results (total_time):
============================================================
  mscn           :    45.2341s  (33% 개선)
  baseline       :    67.8912s
============================================================
```

### Config Sweep 결과

```json
{
  "best_config": {
    "algorithm": "mscn",
    "params": {
      "num_epoch": 100,
      "num_training": 500,
      "num_collection": 500
    },
    "elapsed_time": 42.15
  }
}
```

---

## ⚡ 다음 단계 로드맵

### Phase 1: 기본 기능 (1주) ✅
- [x] 문서 작성
- [x] 스크립트 작성
- [x] 통합 테스트 프레임워크

### Phase 2: 운영 데이터 지원 (2일)
- [ ] ProductionDataset 클래스 구현
- [ ] utils.py 수정
- [ ] 테스트 및 검증

### Phase 3: Training Dataset 유연화 (1주)
- [ ] PresetScheduler 수정 (Mscn, Lero)
- [ ] EventImplement 수정
- [ ] Cross-dataset training 테스트

### Phase 4: Config 최적화 (1주)
- [ ] ConfigGrid 구현
- [ ] Config Sweep 구현
- [ ] 시각화 추가

### Phase 5: 프로덕션 적용 (1주)
- [ ] 성능 벤치마크
- [ ] 모니터링 대시보드
- [ ] 운영 가이드 문서

---

## 🎓 학습 자료

### 기본 개념
1. **PilotScope 아키텍처**: `운영_데이터_기반_최적화_가이드.md` 섹션 1
2. **데이터 흐름**: `운영_데이터_기반_최적화_가이드.md` 부록 A

### 실습
1. **빠른 시작**: `빠른_시작_가이드.md`
2. **커스텀 데이터셋**: `algorithm_examples/CUSTOM_DATASET_GUIDE.md`
3. **결과 관리**: `algorithm_examples/README_RESULTS.md`

### 참고
1. **PilotScope 논문**: `paper/PilotScope.pdf`
2. **API 문서**: https://woodybryant.github.io/PilotScopeDoc.io/

---

## 💬 FAQ

### Q1: 기존 테스트 코드와 어떻게 다른가요?
**A**: 기존 테스트는 개별 알고리즘만 테스트합니다. `unified_test.py`는 여러 알고리즘을 한 번에 비교하고, JSON config로 실험을 관리할 수 있습니다.

### Q2: 운영 DB에 영향을 주나요?
**A**: PilotScope는 읽기 전용으로 쿼리를 실행합니다. 카디널리티 예측은 쿼리 플래너에만 영향을 주고 실제 데이터는 변경하지 않습니다. 그러나 부하가 발생하므로 피크 타임을 피해 테스트하세요.

### Q3: GPU가 필요한가요?
**A**: 선택사항입니다. CPU로도 작동하지만, Lero는 GPU를 사용하면 학습 속도가 10배 이상 빨라집니다.

### Q4: 얼마나 많은 데이터가 필요한가요?
**A**: 
- 최소: 100개 쿼리 (프로토타입)
- 권장: 500-1000개 쿼리 (실험)
- 프로덕션: 1000개 이상 (실전)

### Q5: 결과를 어떻게 해석하나요?
**A**: 
- **total_time 감소**: 쿼리 최적화 성공
- **평균 10-30% 개선**: 일반적인 결과
- **50% 이상 개선**: 매우 좋은 결과 (복잡한 JOIN이 많은 경우)

---

## 📞 지원

- **이슈**: GitHub Issues
- **문서**: 이 디렉토리의 마크다운 파일들
- **예제**: `test_example_algorithms/` 디렉토리

---

**마지막 업데이트**: 2024년 (문서 생성 시점)
**작성자**: AI Assistant
**버전**: 1.0

