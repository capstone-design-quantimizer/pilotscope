# PilotScope 운영 데이터 기반 최적화 가이드

## 목차
1. [아키텍처 개요](#1-아키텍처-개요)
2. [요구사항별 구현 방안](#2-요구사항별-구현-방안)
3. [전체 구현 로드맵](#3-전체-구현-로드맵)
4. [예제 코드](#4-예제-코드)

---

## 1. 아키텍처 개요

### 1.1 PilotScope 핵심 컴포넌트

```
┌─────────────────────────────────────────────────────────┐
│                    PilotScope Core                       │
├─────────────────────────────────────────────────────────┤
│                                                          │
│  ┌──────────────────┐  ┌──────────────────────────┐    │
│  │  PilotScheduler  │  │  PilotDataInteractor     │    │
│  │                  │  │                          │    │
│  │  - execute()     │  │  - push() / pull()       │    │
│  │  - init()        │  │  - execute()             │    │
│  │  - register_*()  │  │                          │    │
│  └────────┬─────────┘  └──────────┬───────────────┘    │
│           │                       │                     │
│  ┌────────┴────────────┬──────────┴──────┬──────────┐  │
│  │                     │                 │          │  │
│  │  PilotConfig        │  PilotEvent    │ Dataset  │  │
│  │  (DB 설정)           │  (학습/수집)    │ (SQL)    │  │
│  │                     │                 │          │  │
│  └─────────────────────┴─────────────────┴──────────┘  │
│                                                          │
└──────────────────────────┬───────────────────────────────┘
                           │
                ┌──────────┴──────────┐
                │                     │
        ┌───────▼──────┐      ┌──────▼───────┐
        │   Database   │      │  AI Models   │
        │              │      │              │
        │  PostgreSQL  │      │  Mscn/Lero   │
        │  / Spark     │      │  /KnobTuning │
        └──────────────┘      └──────────────┘
```

### 1.2 데이터 흐름

```
┌─────────────┐     ┌────────────────┐     ┌─────────────┐
│  SQL Query  │────▶│  PilotScheduler │────▶│  Database   │
└─────────────┘     └───────┬────────┘     └──────┬──────┘
                            │                     │
                            │ ◀───────────────────┘
                            │ (collect data)
                            │
                    ┌───────▼────────┐
                    │   AI Model     │
                    │   (predict)    │
                    └───────┬────────┘
                            │
                            ▼
                    ┌───────────────┐
                    │ Push Modified │
                    │ Card/Plan     │
                    └───────────────┘
```

### 1.3 주요 클래스 설명

#### 1.3.1 **PilotScheduler**
- **역할**: 전체 실행 흐름 관리 (스케줄링)
- **주요 메서드**:
  - `execute(sql)`: SQL 실행 + AI 모델 적용
  - `register_custom_handlers(handlers)`: AI 알고리즘 등록 (Mscn, Lero 등)
  - `register_required_data(...)`: 수집할 데이터 지정 (실행 시간, 카디널리티 등)
  - `register_events(events)`: 학습/수집 이벤트 등록
  - `init()`: 스케줄러 초기화 (사전 학습 시작)

#### 1.3.2 **PresetScheduler Factory Functions**
각 알고리즘마다 사전 구성된 스케줄러 생성 함수:
- `get_mscn_preset_scheduler(config, enable_collection, enable_training, num_collection, num_training, num_epoch)`
- `get_lero_preset_scheduler(config, enable_collection, enable_training, num_collection, num_training, num_epoch)`
- `get_knob_preset_scheduler(config)`

**핵심 매개변수**:
- `config`: DB 연결 설정
- `enable_collection`: 학습 데이터 수집 여부
- `enable_training`: 모델 학습 여부
- `num_collection`: 수집할 학습 SQL 개수 (-1: 전체)
- `num_training`: 학습에 사용할 데이터 개수 (-1: 전체)
- `num_epoch`: 학습 에포크 수

#### 1.3.3 **PilotEvent**
- **PretrainingModelEvent**: 사전 학습 이벤트 (스케줄러 초기화 시 실행)
  - `iterative_data_collection()`: 학습 데이터 수집
  - `custom_model_training()`: 모델 학습
- **PeriodicModelUpdateEvent**: 주기적 모델 업데이트 (동적 학습)

#### 1.3.4 **BaseDataset**
- **역할**: SQL 워크로드 관리
- **주요 메서드**:
  - `read_train_sql()`: 학습용 SQL 읽기
  - `read_test_sql()`: 테스트용 SQL 읽기
  - `load_to_db(config)`: DB에 데이터셋 로드 (최초 1회)

#### 1.3.5 **PilotModel**
- **역할**: AI 모델 래퍼 (저장/로드)
- **주요 메서드**:
  - `save_model()`: 모델 저장
  - `load_model()`: 모델 로드

#### 1.3.6 **TimeStatistic & Result Utilities**
- `TimeStatistic.start(name)` / `end(name)`: 실행 시간 측정
- `TimeStatistic.get_sum_data()`: 누적 시간 데이터
- `save_test_result(algo, db)`: 결과를 JSON으로 저장
- `compare_algorithms(files)`: 여러 알고리즘 결과 비교

---

## 2. 요구사항별 구현 방안

### 2.1 요구사항 1: Best Config 출력 및 성능 측정 데이터

#### 현재 상태
- ✅ 이미 구현됨:
  - `TimeStatistic`: 실행 시간 측정
  - `save_test_result()`: JSON으로 결과 저장
  - `compare_algorithms()`: 여러 알고리즘 비교

#### 개선 필요 사항

##### 2.1.1 **Config 변화에 따른 성능 변화 추적**

**추가 구현 파일**: `algorithm_examples/config_sweep.py`

```python
# 목적: 여러 config 조합을 자동으로 테스트하고 최적 config 찾기
# 
# 기능:
# 1. Config 파라미터 그리드 정의 (예: num_epoch=[50,100,200], learning_rate=[0.001, 0.01])
# 2. 각 config 조합별로 테스트 실행
# 3. 결과를 JSON으로 저장
# 4. 최적 config 자동 선택 (total_time 기준)
# 5. Config vs Performance 시각화
```

**구현 단계**:
1. **파라미터 그리드 정의 클래스** 작성 (`ConfigGrid`)
2. **테스트 러너** 작성 (`run_config_sweep()`)
3. **결과 분석기** 작성 (`analyze_config_results()`)
4. **시각화** 추가 (Heatmap, Line plot)

##### 2.1.2 **실행 계획 변화 추적**

```python
# 추가 데이터 수집:
# - Physical Plan (pull_physical_plan=True)
# - Estimated Cost (pull_estimated_cost=True)
# - Subquery Cardinality (pull_subquery_2_cards=True)
#
# 이를 통해:
# - AI 모델이 변경한 카디널리티 확인
# - 실행 계획 변화 추적
# - Cost 변화 분석
```

**구현 위치**: `algorithm_examples/utils.py`에 `save_detailed_result()` 함수 추가

---

### 2.2 요구사항 2: Dataset/Algorithm을 쉽게 변경

#### 현재 상태
- ✅ 이미 부분적으로 구현됨:
  - `load_test_sql(db)`: dataset 변경
  - `get_mscn_preset_scheduler()` / `get_lero_preset_scheduler()`: algorithm 변경

#### 개선 방안

##### 2.2.1 **통합 테스트 프레임워크**

**추가 구현 파일**: `test_example_algorithms/unified_test.py`

```python
# 목적: 하나의 테스트 파일로 모든 조합 테스트
#
# 사용 예:
# python unified_test.py --algo mscn lero --db stats_tiny imdb --compare
#
# 기능:
# 1. 커맨드라인에서 algorithm/dataset 선택
# 2. 모든 조합 자동 테스트
# 3. 결과 자동 비교
# 4. 요약 리포트 생성
```

**구현 요소**:
```python
ALGORITHM_REGISTRY = {
    "mscn": get_mscn_preset_scheduler,
    "lero": get_lero_preset_scheduler,
    "knob": get_knob_preset_scheduler,
    "baseline": None  # No AI model
}

DATASET_REGISTRY = {
    "stats_tiny": StatsTinyDataset,
    "stats": StatsDataset,
    "imdb": ImdbDataset,
    "tpcds": TpcdsDataset
}
```

##### 2.2.2 **Config 파일 기반 테스트**

**추가 파일**: `test_configs/experiment_config.json`

```json
{
  "experiments": [
    {
      "name": "exp1_mscn_stats",
      "algorithm": "mscn",
      "dataset": "stats_tiny",
      "params": {
        "enable_collection": true,
        "enable_training": true,
        "num_epoch": 100
      }
    },
    {
      "name": "exp2_lero_imdb",
      "algorithm": "lero",
      "dataset": "imdb",
      "params": {
        "enable_collection": true,
        "enable_training": true,
        "num_epoch": 50
      }
    }
  ]
}
```

실행:
```bash
python unified_test.py --config test_configs/experiment_config.json
```

---

### 2.3 요구사항 3: 임의의 데이터셋 추가

#### 현재 상태
✅ 이미 구현됨 - `CUSTOM_DATASET_GUIDE.md`에 자세한 가이드 있음

#### 운영 데이터 추가 프로세스

##### Step 1: 운영 DB 쿼리 로그 수집

```sql
-- PostgreSQL에서 쿼리 로그 활성화
ALTER SYSTEM SET log_statement = 'all';
ALTER SYSTEM SET log_min_duration_statement = 0;  -- 모든 쿼리 로그
SELECT pg_reload_conf();

-- 로그 수집 (하루 동안)
-- 위치: /var/log/postgresql/postgresql-{date}.log
```

##### Step 2: 로그에서 SQL 추출

**스크립트 추가**: `scripts/extract_queries_from_log.py`

```python
# 기능:
# 1. PostgreSQL 로그 파일 파싱
# 2. SELECT 쿼리만 추출
# 3. 중복 제거 및 파라미터화
# 4. train/test 분할 (8:2)
# 5. .txt 파일로 저장
#
# 사용:
# python scripts/extract_queries_from_log.py \
#     --input /var/log/postgresql/postgresql.log \
#     --output pilotscope/Dataset/Production/
```

##### Step 3: Dataset 클래스 작성

**파일**: `pilotscope/Dataset/ProductionDataset.py`

```python
from pilotscope.Dataset.BaseDataset import BaseDataset
from pilotscope.PilotEnum import DatabaseEnum

class ProductionDataset(BaseDataset):
    """
    실제 운영 환경의 쿼리 워크로드.
    """
    sub_dir = "Production"
    train_sql_file = "production_train.txt"
    test_sql_file = "production_test.txt"
    file_db_type = DatabaseEnum.POSTGRESQL
    
    def __init__(self, use_db_type: DatabaseEnum, created_db_name="production_db"):
        super().__init__(use_db_type, created_db_name)
        self.download_urls = None  # 이미 존재하는 DB 사용
```

##### Step 4: Utils에 등록

**수정 파일**: `algorithm_examples/utils.py`

```python
from pilotscope.Dataset.ProductionDataset import ProductionDataset

def load_test_sql(db):
    # ... 기존 코드 ...
    elif "production" == db.lower():
        return ProductionDataset(DatabaseEnum.POSTGRESQL).read_test_sql()
    # ...

def load_training_sql(db):
    # ... 기존 코드 ...
    elif "production" == db.lower():
        return ProductionDataset(DatabaseEnum.POSTGRESQL).read_train_sql()
    # ...
```

##### Step 5: 사용

```python
# 테스트 실행
config = PostgreSQLConfig()
config.db = "production_db"  # 운영 DB 이름

scheduler = get_mscn_preset_scheduler(config, 
                                      enable_collection=True, 
                                      enable_training=True)

sqls = load_test_sql("production")
for sql in sqls:
    scheduler.execute(sql)
```

---

### 2.4 요구사항 4: 개별 모델의 Training Dataset 변경

#### 현재 상태
✅ 부분적으로 구현됨 - `PretrainingModelEvent`에서 `load_training_sql()` 호출

#### 변경 방법

##### 방법 1: PresetScheduler 파라미터로 지정

**수정 파일**: `algorithm_examples/Mscn/MscnPresetScheduler.py`

```python
def get_mscn_preset_scheduler(config, 
                             enable_collection, 
                             enable_training, 
                             num_collection=-1, 
                             num_training=-1, 
                             num_epoch=100,
                             training_dataset="auto"):  # 추가!
    """
    training_dataset: 학습에 사용할 데이터셋
      - "auto": config.db와 동일
      - "stats_tiny", "imdb" 등: 지정한 데이터셋 사용
      - "production": 운영 데이터 사용
    """
    # ...
    pretraining_event = MscnPretrainingModelEvent(
        config, 
        mscn_pilot_model, 
        pretrain_data_save_table,
        enable_collection=enable_collection,
        enable_training=enable_training,
        training_dataset=training_dataset,  # 전달!
        # ...
    )
```

**수정 파일**: `algorithm_examples/Mscn/EventImplement.py`

```python
class MscnPretrainingModelEvent(PretrainingModelEvent):
    def __init__(self, config, bind_pilot_model, data_saving_table, 
                 enable_collection=True, enable_training=True,
                 training_data_file=None, 
                 num_collection=-1, num_training=-1, num_epoch=100,
                 training_dataset="auto"):  # 추가!
        super().__init__(config, bind_pilot_model, data_saving_table, 
                        enable_collection, enable_training)
        # ...
        self.training_dataset = training_dataset
    
    def iterative_data_collection(self, db_controller, train_data_manager):
        print("start to collect data for MSCN algorithms")
        
        # 학습 데이터셋 결정
        if self.training_dataset == "auto":
            dataset_name = self.config.db
        else:
            dataset_name = self.training_dataset
        
        self.sqls = load_training_sql(dataset_name)  # 변경!
        # ...
```

**사용 예**:
```python
# 예1: stats_tiny DB에서 테스트하지만, imdb 데이터로 학습
config.db = "stats_tiny"  # 테스트 DB
scheduler = get_mscn_preset_scheduler(config, 
                                      enable_collection=True, 
                                      enable_training=True,
                                      training_dataset="imdb")  # 학습 데이터는 IMDB

# 예2: 운영 DB에서 테스트하고, 운영 로그로 학습
config.db = "production_db"
scheduler = get_mscn_preset_scheduler(config, 
                                      enable_collection=True, 
                                      enable_training=True,
                                      training_dataset="production")
```

##### 방법 2: 외부 파일 직접 지정

```python
# 이미 구현됨 - training_data_file 파라미터 사용
scheduler = get_mscn_preset_scheduler(config, 
                                      enable_collection=False,  # 파일 사용
                                      enable_training=True,
                                      training_data_file="/path/to/custom_train.txt")
```

---

## 3. 전체 구현 로드맵

### Phase 1: 기본 인프라 구축 (1주)
- [x] 프레임워크 구조 분석
- [ ] 운영 쿼리 로그 추출 스크립트 (`scripts/extract_queries_from_log.py`)
- [ ] ProductionDataset 클래스 작성
- [ ] utils.py에 production dataset 등록

### Phase 2: Config 최적화 (1주)
- [ ] ConfigGrid 클래스 (`algorithm_examples/config_grid.py`)
- [ ] Config Sweep 실행기 (`algorithm_examples/config_sweep.py`)
- [ ] 결과 분석 및 시각화 기능
- [ ] Best Config 자동 선택 기능

### Phase 3: 통합 테스트 프레임워크 (1주)
- [ ] Unified Test 프레임워크 (`test_example_algorithms/unified_test.py`)
- [ ] Algorithm Registry 구현
- [ ] Dataset Registry 구현
- [ ] JSON Config 파일 지원

### Phase 4: 상세 데이터 수집 (1주)
- [ ] `save_detailed_result()` 구현
- [ ] Physical Plan 저장
- [ ] Cardinality 변화 추적
- [ ] 실행 계획 Diff 시각화

### Phase 5: Training Dataset 유연화 (1주)
- [ ] PresetScheduler에 `training_dataset` 파라미터 추가
- [ ] EventImplement 수정
- [ ] Cross-dataset training 테스트

### Phase 6: 통합 및 검증 (1주)
- [ ] End-to-End 테스트
- [ ] 문서화 완성
- [ ] 예제 시나리오 작성

---

## 4. 예제 코드

### 4.1 운영 데이터 기반 최적화 시나리오

```python
"""
시나리오: 
1. 운영 DB의 쿼리 로그 수집
2. 여러 알고리즘(Mscn, Lero) 테스트
3. 다양한 Config 조합 시도
4. 최적 알고리즘 + Config 선택
"""

# Step 1: 운영 쿼리 로그 추출
!python scripts/extract_queries_from_log.py \
    --input /var/log/postgresql/postgresql.log \
    --output pilotscope/Dataset/Production/ \
    --train-ratio 0.8

# Step 2: ProductionDataset 사용
from pilotscope.PilotConfig import PostgreSQLConfig
from pilotscope.Dataset.ProductionDataset import ProductionDataset

config = PostgreSQLConfig()
config.db = "production_db"

# Step 3: Config Sweep 실행
from algorithm_examples.config_sweep import run_config_sweep

configs = {
    "num_epoch": [50, 100, 200],
    "num_collection": [100, 500, 1000],
    "num_training": [100, 500, 1000]
}

algorithms = ["mscn", "lero"]
dataset = "production"

results = run_config_sweep(
    algorithms=algorithms,
    dataset=dataset,
    config_grid=configs,
    db_config=config
)

# Step 4: 최적 Config 선택
best_config = results.get_best_config(metric="total_time")
print(f"Best Config: {best_config}")
print(f"Best Algorithm: {best_config['algorithm']}")
print(f"Best Parameters: {best_config['params']}")

# Step 5: 최적 Config로 재실행
from algorithm_examples.Mscn.MscnPresetScheduler import get_mscn_preset_scheduler

scheduler = get_mscn_preset_scheduler(
    config,
    enable_collection=True,
    enable_training=True,
    **best_config['params']  # 최적 파라미터 적용
)

sqls = load_test_sql("production")
for sql in sqls:
    scheduler.execute(sql)

save_test_result("mscn_optimized", "production")
```

### 4.2 Cross-Dataset Training

```python
"""
시나리오: 
IMDB 데이터로 학습한 모델을 운영 DB에 적용
"""

from pilotscope.PilotConfig import PostgreSQLConfig
from algorithm_examples.Mscn.MscnPresetScheduler import get_mscn_preset_scheduler
from algorithm_examples.utils import load_test_sql, save_test_result

config = PostgreSQLConfig()
config.db = "production_db"  # 테스트할 DB

# IMDB 데이터로 학습
scheduler = get_mscn_preset_scheduler(
    config,
    enable_collection=True,
    enable_training=True,
    training_dataset="imdb",  # 학습 데이터는 IMDB
    num_epoch=100
)

# 운영 DB에서 테스트
sqls = load_test_sql("production")
for sql in sqls:
    scheduler.execute(sql)

save_test_result("mscn_imdb_trained", "production")
```

### 4.3 통합 테스트 실행

```bash
# 방법 1: 커맨드라인
python test_example_algorithms/unified_test.py \
    --algo mscn lero baseline \
    --db stats_tiny production \
    --compare \
    --output results/multi_algo_comparison

# 방법 2: Config 파일
python test_example_algorithms/unified_test.py \
    --config test_configs/production_experiment.json
```

**Config 파일 예시**: `test_configs/production_experiment.json`
```json
{
  "db_config": {
    "db_type": "postgresql",
    "db": "production_db",
    "host": "localhost",
    "port": "5432"
  },
  "experiments": [
    {
      "name": "baseline",
      "algorithm": "baseline",
      "dataset": "production"
    },
    {
      "name": "mscn_default",
      "algorithm": "mscn",
      "dataset": "production",
      "params": {
        "enable_collection": true,
        "enable_training": true,
        "num_epoch": 100
      }
    },
    {
      "name": "mscn_imdb_trained",
      "algorithm": "mscn",
      "dataset": "production",
      "params": {
        "enable_collection": true,
        "enable_training": true,
        "training_dataset": "imdb",
        "num_epoch": 100
      }
    },
    {
      "name": "lero_default",
      "algorithm": "lero",
      "dataset": "production",
      "params": {
        "enable_collection": true,
        "enable_training": true,
        "num_epoch": 50
      }
    }
  ],
  "comparison": {
    "metrics": ["total_time", "average_time"],
    "output_dir": "results/production_comparison"
  }
}
```

---

## 5. 핵심 파일 수정/추가 요약

### 5.1 새로 추가할 파일

| 파일 경로 | 목적 | 우선순위 |
|----------|------|---------|
| `scripts/extract_queries_from_log.py` | 운영 로그에서 SQL 추출 | 높음 |
| `pilotscope/Dataset/Production/production_train.txt` | 운영 학습 SQL | 높음 |
| `pilotscope/Dataset/Production/production_test.txt` | 운영 테스트 SQL | 높음 |
| `pilotscope/Dataset/ProductionDataset.py` | 운영 데이터셋 클래스 | 높음 |
| `algorithm_examples/config_grid.py` | Config 그리드 클래스 | 중간 |
| `algorithm_examples/config_sweep.py` | Config sweep 실행기 | 중간 |
| `test_example_algorithms/unified_test.py` | 통합 테스트 프레임워크 | 중간 |
| `test_configs/production_experiment.json` | 실험 설정 파일 | 낮음 |

### 5.2 수정할 파일

| 파일 경로 | 수정 내용 | 우선순위 |
|----------|---------|---------|
| `algorithm_examples/utils.py` | `load_test_sql()`, `load_training_sql()`에 production 추가 | 높음 |
| `algorithm_examples/Mscn/MscnPresetScheduler.py` | `training_dataset` 파라미터 추가 | 중간 |
| `algorithm_examples/Mscn/EventImplement.py` | `training_dataset` 처리 로직 추가 | 중간 |
| `algorithm_examples/Lero/LeroPresetScheduler.py` | `training_dataset` 파라미터 추가 | 중간 |
| `algorithm_examples/Lero/EventImplement.py` | `training_dataset` 처리 로직 추가 | 중간 |

---

## 6. 실행 가이드

### 6.1 빠른 시작 (운영 데이터 기반)

```bash
# 1. 운영 쿼리 로그 추출
python scripts/extract_queries_from_log.py \
    --input /var/log/postgresql/postgresql.log \
    --output pilotscope/Dataset/Production/

# 2. 베이스라인 성능 측정
cd test_example_algorithms
python test_baseline_performance.py  # config.db = "production_db"로 수정 필요

# 3. MSCN 알고리즘 테스트
python test_mscn_example.py  # config.db = "production_db"로 수정 필요

# 4. 결과 비교
cd ../algorithm_examples
python compare_results.py --latest baseline mscn
```

### 6.2 Config 최적화

```bash
# Config sweep 실행
python algorithm_examples/config_sweep.py \
    --algo mscn \
    --db production \
    --param num_epoch 50 100 200 \
    --param num_training 100 500 1000 \
    --output results/config_sweep

# 결과 분석
python algorithm_examples/analyze_config_sweep.py \
    --input results/config_sweep/sweep_results.json
```

---

## 7. 문제 해결 가이드

### 7.1 일반적인 문제

#### Q1: 운영 DB에 연결이 안됨
```python
# pilotscope_conf.json 확인
{
  "PostgreSQLConfig": {
    "db_host": "your_production_host",
    "db_port": "5432",
    "db_user": "your_user",
    "db_user_pwd": "your_password"
  }
}
```

#### Q2: 학습 데이터가 너무 많아서 시간이 오래 걸림
```python
# num_collection, num_training 파라미터로 제한
scheduler = get_mscn_preset_scheduler(
    config,
    enable_collection=True,
    enable_training=True,
    num_collection=1000,  # 수집은 1000개만
    num_training=500,     # 학습은 500개만
    num_epoch=50          # Epoch도 줄이기
)
```

#### Q3: 메모리 부족
```python
# 배치로 나눠서 실행
sqls = load_test_sql("production")
batch_size = 100

for i in range(0, len(sqls), batch_size):
    batch_sqls = sqls[i:i+batch_size]
    for sql in batch_sqls:
        scheduler.execute(sql)
    
    # 중간 결과 저장
    save_test_result(f"mscn_batch_{i//batch_size}", "production")
```

### 7.2 성능 최적화 팁

1. **학습 데이터 캐싱**: 한 번 수집한 데이터는 재사용
   ```python
   # 첫 실행: 데이터 수집 + 학습
   scheduler = get_mscn_preset_scheduler(config, 
                                        enable_collection=True, 
                                        enable_training=True)
   
   # 이후 실행: 기존 데이터로 재학습
   scheduler = get_mscn_preset_scheduler(config, 
                                        enable_collection=False,  # 수집 생략
                                        enable_training=True)
   ```

2. **GPU 사용** (Lero):
   ```python
   # Lero는 PyTorch 사용 -> GPU 자동 감지
   import torch
   print(f"GPU available: {torch.cuda.is_available()}")
   ```

3. **병렬 실행**:
   ```bash
   # 여러 알고리즘을 동시에 테스트
   python test_mscn_example.py &
   python test_lero_example.py &
   wait
   python compare_results.py --latest mscn lero
   ```

---

## 8. 결론

### 8.1 최종 목표 달성 방안

```
┌─────────────────────────────────────────────────────────┐
│              운영 데이터 기반 최적화 워크플로우              │
└─────────────────────────────────────────────────────────┘

1. 운영 로그 수집
   ↓
2. ProductionDataset 생성
   ↓
3. 여러 알고리즘 테스트 (Baseline, Mscn, Lero)
   ↓
4. Config Sweep으로 최적 파라미터 탐색
   ↓
5. Cross-Dataset Training 시도
   ↓
6. 결과 비교 및 Best Config 선택
   ↓
7. 운영 환경 적용
```

### 8.2 구현 체크리스트

- [ ] **요구사항 1 (Best Config 출력)**
  - [ ] Config Sweep 기능 구현
  - [ ] 상세 성능 데이터 수집 (Plan, Cost, Card)
  - [ ] Best Config 자동 선택 기능

- [ ] **요구사항 2 (Dataset/Algorithm 변경)**
  - [ ] Unified Test 프레임워크
  - [ ] Algorithm/Dataset Registry
  - [ ] JSON Config 파일 지원

- [ ] **요구사항 3 (임의 데이터셋 추가)**
  - [ ] 운영 로그 추출 스크립트
  - [ ] ProductionDataset 클래스
  - [ ] utils.py 등록

- [ ] **요구사항 4 (Training Dataset 변경)**
  - [ ] PresetScheduler에 training_dataset 파라미터
  - [ ] EventImplement 수정
  - [ ] Cross-dataset training 테스트

### 8.3 예상 효과

- ✅ **운영 데이터 기반 최적화**: 실제 워크로드에 맞는 모델 학습
- ✅ **자동화된 Config 탐색**: 수동 튜닝 없이 최적 설정 발견
- ✅ **유연한 실험 환경**: 다양한 알고리즘/데이터 조합 쉽게 테스트
- ✅ **재사용 가능한 모델**: 한 데이터셋으로 학습 → 다른 DB 적용

---

## 부록 A: 아키텍처 다이어그램

### A.1 전체 시스템 아키텍처

```
┌───────────────────────────────────────────────────────────────┐
│                      User Interface Layer                      │
├───────────────────────────────────────────────────────────────┤
│  test_mscn_example.py  │  unified_test.py  │  config_sweep.py │
└───────────────────────────────────────────────────────────────┘
                              │
              ┌───────────────┴───────────────┐
              │                               │
┌─────────────▼──────────┐    ┌──────────────▼────────────┐
│  PresetScheduler       │    │  Dataset Management       │
│  - get_mscn_preset..() │    │  - load_test_sql()        │
│  - get_lero_preset..() │    │  - load_training_sql()    │
└─────────────┬──────────┘    └──────────────┬────────────┘
              │                               │
              └───────────────┬───────────────┘
                              │
              ┌───────────────▼───────────────┐
              │      PilotScheduler           │
              │  - execute()                  │
              │  - register_custom_handlers() │
              │  - register_events()          │
              └───────────────┬───────────────┘
                              │
              ┌───────────────┼───────────────┐
              │               │               │
  ┌───────────▼────┐  ┌───────▼──────┐  ┌───▼─────────┐
  │ AnchorHandler  │  │ PilotEvent   │  │ DataManager │
  │ (Mscn/Lero)    │  │ (Training)   │  │             │
  └───────────┬────┘  └───────┬──────┘  └───┬─────────┘
              │               │             │
              └───────────────┼─────────────┘
                              │
              ┌───────────────▼───────────────┐
              │    PilotDataInteractor        │
              │    - push() / pull()          │
              │    - execute()                │
              └───────────────┬───────────────┘
                              │
              ┌───────────────▼───────────────┐
              │         Database              │
              │    (PostgreSQL / Spark)       │
              └───────────────────────────────┘
```

### A.2 데이터 수집 및 학습 흐름

```
[Scheduler 초기화]
    │
    ├─→ register_custom_handlers(MscnCardPushHandler)
    │   - AI 모델을 PushHandler로 등록
    │
    ├─→ register_events(PretrainingModelEvent)
    │   - 사전 학습 이벤트 등록
    │
    └─→ init()
        │
        └─→ PretrainingModelEvent._async_start()
            │
            ├─→ 1. iterative_data_collection()
            │   │  - load_training_sql()로 SQL 로드
            │   │  - 각 SQL 실행하여 실제 카디널리티 수집
            │   │  - DataManager에 저장
            │   │
            │   └─→ 2. custom_model_training()
            │       - DataManager에서 학습 데이터 읽기
            │       - 모델 학습 (MscnModel.fit())
            │       - 모델 저장 (save_model())
            │
            └─→ [학습 완료 - 메인 스레드 계속]

[쿼리 실행 단계]
    │
    └─→ scheduler.execute(sql)
        │
        ├─→ MscnCardPushHandler._update_injected_data(sql)
        │   - 모델로 카디널리티 예측
        │   - 예측값을 Push 데이터로 준비
        │
        ├─→ data_interactor.execute(sql)
        │   - Push Handler: 예측 카디널리티를 DB에 주입
        │   - DB: 주입된 카디널리티로 쿼리 최적화
        │   - DB: 쿼리 실행
        │   - Pull Handler: 실행 시간 등 수집
        │
        └─→ save result to DataManager
```

### A.3 Config Sweep 프로세스

```
[Config Sweep 시작]
    │
    ├─→ ConfigGrid 생성
    │   {
    │     "num_epoch": [50, 100, 200],
    │     "num_collection": [100, 500, 1000]
    │   }
    │   → 총 3×3 = 9개 조합
    │
    ├─→ For each config combination:
    │   │
    │   ├─→ 1. PresetScheduler 생성 (with current config)
    │   │
    │   ├─→ 2. 테스트 실행
    │   │   - TimeStatistic.start()
    │   │   - for sql in test_sqls: scheduler.execute(sql)
    │   │   - TimeStatistic.end()
    │   │
    │   ├─→ 3. 결과 저장
    │   │   - save_test_result(f"mscn_config_{i}", db)
    │   │
    │   └─→ 4. 정리 (메모리 해제)
    │
    ├─→ 모든 결과 비교
    │   - 각 config별 total_time 추출
    │   - 최소 시간 찾기
    │
    └─→ Best Config 반환
        {
          "algorithm": "mscn",
          "params": {"num_epoch": 100, "num_collection": 500},
          "total_time": 45.23
        }
```

---

이 문서를 참고하여 단계적으로 구현하시면 됩니다. 궁금한 점이 있으시면 언제든 질문해 주세요!

